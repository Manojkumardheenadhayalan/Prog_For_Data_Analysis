{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10853081,"sourceType":"datasetVersion","datasetId":6740894}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install streamlit\n!npm install -g localtunnel\n!pip install streamlit_folium\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%writefile app.py\n# import streamlit as st\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# # Sample data: Example coordinates and features for each location\n# location_data = {\n#     \"Data_Wanliu\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanliu_20130301-20170228.csv\",\n#     \"Data_Wanshouxigong\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanshouxigong_20130301-20170228.csv\",\n#     \"Data_Aotizhongxin\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Aotizhongxin_20130301-20170228.csv\",\n#     \"Data_Changping\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Changping_20130301-20170228.csv\",\n#     \"Data_Dingling\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dingling_20130301-20170228.csv\",\n#     \"Data_Dongsi\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dongsi_20130301-20170228.csv\",\n#     \"Data_Guanyuan\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Guanyuan_20130301-20170228.csv\",\n#     \"Data_Gucheng\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Gucheng_20130301-20170228.csv\",\n#     \"Data_Huairou\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Huairou_20130301-20170228.csv\",\n#     \"Data_Nongzhanguan\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Nongzhanguan_20130301-20170228.csv\",\n#     \"Data_Shunyi\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Shunyi_20130301-20170228.csv\",\n#     \"Data_Tiantan\": \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Tiantan_20130301-20170228.csv\"\n# }\n\n# # Streamlit app layout\n# st.title(\"Air Quality Data EDA\")\n\n# # Display AQI for all locations\n# st.subheader(\"Air Quality Index (AQI) for all regions\")\n# aqi_data = {}\n\n# # Load and show AQI for all locations\n# for location, file_path in location_data.items():\n#     try:\n#         data = pd.read_csv(file_path)\n#         aqi_data[location] = data['PM2.5'].mean()  # Assuming 'PM2.5' column as AQI indicator\n#     except Exception as e:\n#         aqi_data[location] = f\"Error: {e}\"\n\n# # Show AQI data in a table\n# aqi_df = pd.DataFrame(list(aqi_data.items()), columns=[\"Location\", \"Average AQI (PM2.5)\"])\n# st.write(aqi_df)\n\n# # Allow the user to select 5 locations\n# selected_locations = st.multiselect(\n#     \"Choose any five locations for EDA:\",\n#     list(location_data.keys()),\n#     max_selections=5  # Limit the selection to 5 locations\n# )\n\n# # If the user selects locations\n# if selected_locations:\n#     merged_data = pd.DataFrame()  # Initialize an empty DataFrame for merged data\n    \n#     # Load and merge the selected datasets\n#     for location in selected_locations:\n#         file_path = location_data[location]\n#         try:\n#             data = pd.read_csv(file_path)\n#             data['Location'] = location  # Add location column for tracking\n#             merged_data = pd.concat([merged_data, data], ignore_index=True)\n#         except Exception as e:\n#             st.write(f\"Error reading the file for {location}: {e}\")\n    \n#     # Show merged data preview\n#     st.subheader(\"Merged Data Preview\")\n#     st.write(merged_data.head())\n\n#     # Dropdown for selecting the region to focus on after merging\n#     selected_region = st.selectbox(\n#         \"Select a region for EDA\",\n#         merged_data['Location'].unique()\n#     )\n\n#     # Filter the merged data based on the selected region\n#     region_data = merged_data[merged_data['Location'] == selected_region]\n\n#     # Perform EDA on the selected region's data\n#     st.subheader(f\"Performing EDA for {selected_region}\")\n\n#     # Show first few rows\n#     st.subheader(f\"First few rows of {selected_region} data:\")\n#     st.write(region_data.head())\n\n#     # Summary statistics\n#     st.subheader(f\"Summary Statistics of {selected_region} data:\")\n#     st.write(region_data.describe())\n\n#     # Check for missing values\n#     st.subheader(f\"Missing Values in {selected_region} data:\")\n#     st.write(region_data.isnull().sum())\n\n#     # Visualizations\n#     st.subheader(f\"Visualizations for {selected_region} data:\")\n    \n#     # Plot histograms for each numerical column\n#     st.write(\"Histograms of numerical features:\")\n#     numeric_columns = region_data.select_dtypes(include=['float64', 'int64']).columns\n#     for col in numeric_columns:\n#         st.write(f\"Histogram of {col}:\")\n#         fig, ax = plt.subplots()\n#         region_data[col].hist(bins=30, ax=ax)\n#         ax.set_title(f\"Histogram of {col}\")\n#         st.pyplot(fig)\n\n#     # Plot a correlation heatmap\n#     st.write(\"Correlation Heatmap:\")\n#     corr = region_data.corr()\n#     fig, ax = plt.subplots(figsize=(10, 8))\n#     sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)\n#     st.pyplot(fig)\n\n#     # Show a boxplot of the first numerical column\n#     if len(numeric_columns) > 0:\n#         st.write(f\"Boxplot of {numeric_columns[0]}:\")\n#         fig, ax = plt.subplots()\n#         sns.boxplot(x=region_data[numeric_columns[0]], ax=ax)\n#         ax.set_title(f\"Boxplot of {numeric_columns[0]}\")\n#         st.pyplot(fig)\n\n# else:\n#     st.write(\"Please select at least one location to perform EDA.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom streamlit_folium import folium_static\n\nlocation_data = {\n    \"Data_Wanliu\": (39.974, 116.311, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanliu_20130301-20170228.csv\"),\n    \"Data_Wanshouxigong\": (39.889, 116.352, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Wanshouxigong_20130301-20170228.csv\"),\n    \"Data_Aotizhongxin\": (40.007, 116.397, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Aotizhongxin_20130301-20170228.csv\"),\n    \"Data_Changping\": (40.22, 116.23, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Changping_20130301-20170228.csv\"),\n    \"Data_Dingling\": (40.29, 116.22, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dingling_20130301-20170228.csv\"),\n    \"Data_Dongsi\": (39.93, 116.42, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Dongsi_20130301-20170228.csv\"),\n    \"Data_Guanyuan\": (39.93, 116.36, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Guanyuan_20130301-20170228.csv\"),\n    \"Data_Gucheng\": (39.91, 116.18, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Gucheng_20130301-20170228.csv\"),\n    \"Data_Huairou\": (40.31, 116.63, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Huairou_20130301-20170228.csv\"),\n    \"Data_Nongzhanguan\": (39.93, 116.47, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Nongzhanguan_20130301-20170228.csv\"),\n    \"Data_Shunyi\": (40.13, 116.65, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Shunyi_20130301-20170228.csv\"),\n    \"Data_Tiantan\": (39.88, 116.41, \"/kaggle/input/beijing-air-quality-data-dataset/PRSA2017_Data_20130301-20170228/PRSA_Data_20130301-20170228/PRSA_Data_Tiantan_20130301-20170228.csv\")\n}\n\n# Streamlit app layout\nst.title(\"Air Quality Data EDA\")\n\n# User selects locations\nselected_locations = st.multiselect(\n    \"Choose any locations for EDA:\",\n    list(location_data.keys())\n)\n\nif selected_locations:\n    merged_data = pd.DataFrame()\n    for location in selected_locations:\n        _, _, file_path = location_data[location]\n        try:\n            data = pd.read_csv(file_path)\n            data['Location'] = location\n            merged_data = pd.concat([merged_data, data], ignore_index=True)\n        except Exception as e:\n            st.write(f\"Error reading the file for {location}: {e}\")\n    \n    # Show merged data preview\n    st.subheader(\"Merged Data Preview\")\n    st.write(merged_data.head())\n    \n    # Perform EDA on merged data\n    st.subheader(\"Performing EDA on Merged Data\")\n    st.write(merged_data.describe())\n    st.write(merged_data.isnull().sum())\n    \n    # Visualizations\n    numeric_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n    for col in numeric_columns:\n        fig, ax = plt.subplots()\n        merged_data[col].hist(bins=30, ax=ax)\n        ax.set_title(f\"Histogram of {col}\")\n        st.pyplot(fig)\n    \n    corr = merged_data.corr()\n    fig, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)\n    st.pyplot(fig)\n    \n    # Individual dataset selection for EDA\n    selected_region = st.selectbox(\"Select a region for individual EDA\", selected_locations)\n    if selected_region:\n        region_data = merged_data[merged_data['Location'] == selected_region]\n        st.subheader(f\"EDA for {selected_region}\")\n        st.write(region_data.describe())\n        st.write(region_data.isnull().sum())\n        \n        for col in numeric_columns:\n            fig, ax = plt.subplots()\n            region_data[col].hist(bins=30, ax=ax)\n            ax.set_title(f\"Histogram of {col}\")\n            st.pyplot(fig)\n        \n        fig, ax = plt.subplots(figsize=(10, 8))\n        sns.heatmap(region_data.corr(), annot=True, cmap='coolwarm', ax=ax)\n        st.pyplot(fig)\nelse:\n    st.write(\"Please select at least one location to perform EDA.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!wget -q -O - ipv4.icanhazip.com","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!streamlit run app.py & npx localtunnel --port 8501","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}